{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeshGraphNets: Learning Mesh-based Simulation with Graph Networks\n",
    "\n",
    "## I. Introduction\n",
    "Finite element simulations are a standard for modeling mesh systems, but they are expensive and often domain specific.\n",
    "Graph neural networks can learn the underlying dynamics in a domain agnostic way and with much cheaper inference.\n",
    "\n",
    "## II. Background\n",
    "\n",
    "### II.A. Traditional Simulation Methods\n",
    "Conventional partial differential equation solvers iteratively compute the system’s state but scale quickly in computational cost with mesh size and resolution.\n",
    "They are however fairly accurate, interpretable and stable even on long rollouts, as they directly encode the physical laws underlying the modeled interactions.\n",
    "\n",
    "### II.B. Graph Neural Networks\n",
    "Graph-structured data presents challenges to common machine learning approaches. Naively processing an adjacency matrix with MLPs discards much of the structure, does not generalize to graphs of different sizes and quickly becomes computationally intractable.\n",
    "Instead the paradigm of message-passing has emerged, wherein each node is embedded individually and then updated by aggregation of embeddings from adjacent nodes.\n",
    "The concrete embedding and aggregation scheme is a degree of freedom and several architectures have been proposed, including siblings of non-geometric ML ideas, such as:\n",
    "- Graph Convolution: sum of neighbors, weighted by the root of the degree of both nodes.\n",
    "- Graph Attention: learnable weighted sum of adjacent embeddings.\n",
    "Since each GNN block processes a single hop, the receptive field at each node is simply the number of layers.\n",
    "Typically this is limited, forcing the network to learn local dynamics, which helps in generalization and prevents oversmoothing of predictions.\n",
    "\n",
    "### II.C. Adaptive Remeshing\n",
    "Depending on local complexity, different regions of the mesh require different resolutions to balance accuracy and computational cost.\n",
    "Adaptive meshing refines or coarsens regions based on different criteria expressed through a sizing field. Traditionally this requires domain knowledge, but the sizing field can also be learned to loosen this restriction. (Implementation not published)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Domains and Datasets\n",
    "The authors evaluate on cloth simulation, structural deformation, and both compressible and incompressible fluid dynamics. The training data is generated from different simulators.\n",
    "The method is capable of handling different domains with minimal, if any, adaptation. Many of the problems application even use the same hyperparameters.\n",
    "\n",
    "| Dataset        | System      | Solver | Mesh Type   | Meshing      | # Steps | ∆t/s |\n",
    "|----------------|-------------|--------|-------------|--------------|---------|-------|\n",
    "| FLAGSIMPLE     | cloth       | ArcSim | triangle    | 3D regular   | 400     | 0.02  |\n",
    "| FLAGDYNAMIC    | cloth       | ArcSim | triangle    | 3D dynamic   | 250     | 0.02  |\n",
    "| SPHEREDYNAMIC  | cloth       | ArcSim | triangle    | 3D dynamic   | 500     | 0.01  |\n",
    "| DEFORMINGPLATE | hyper-el.   | COMSOL | tetrahedral | 3D irregular | 400     | —     |\n",
    "| CYLINDERFLOW   | incompr. NS | COMSOL | triangle    | 2D irregular | 600     | 0.01  |\n",
    "| AIRFOIL        | compr. NS   | SU2    | triangle    | 2D irregular | 600     | 0.008 |\n",
    "\n",
    "This notebook uses the example of cylinderflow.\n",
    "The specific dataset is a timeseries $[g_0, ... g_n]$\n",
    "Where each $g_i$ consists of:\n",
    "- x (node features): 2D velocity + one hot encodeded node type. Shape: [n_nodes, 11]\n",
    "- edge index: adjacency. Shape: [2, n_edges]\n",
    "- edge attributes. 2D position + 2-norm. Shape: [n_edges, 3]\n",
    "- y (node outputs). Difference in fluid acceleration to next step. Shape: [n_nodes, 2]\n",
    "- p (pressure): Unused. Shape: [n_nodes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import enum\n",
    "\n",
    "class NodeType(enum.IntEnum):\n",
    "    NORMAL = 0\n",
    "    OBSTACLE = 1\n",
    "    AIRFOIL = 2\n",
    "    HANDLE = 3\n",
    "    INFLOW = 4\n",
    "    OUTFLOW = 5\n",
    "    WALL_BOUNDARY = 6\n",
    "    SIZE = 9\n",
    "\n",
    "\n",
    "DATAPATH = \"../data/\"\n",
    "def load_dataset():\n",
    "    return torch.load(DATAPATH + \"meshgraphnets_miniset5traj_vis.pt\", weights_only=False)\n",
    "\n",
    "def load_testset():\n",
    "    return torch.load(DATAPATH + \"test_processed_set.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 2995\n",
      "x shape: torch.Size([1923, 11])\n",
      "edge_index shape: torch.Size([2, 11070])\n",
      "edge_attr shape: torch.Size([11070, 3])\n",
      "y shape: torch.Size([1923, 2])\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "print(\"dataset size:\", len(dataset))\n",
    "print(\"x shape:\", dataset[0].x.shape)\n",
    "print(\"edge_index shape:\", dataset[0].edge_index.shape)\n",
    "print(\"edge_attr shape:\", dataset[0].edge_attr.shape)\n",
    "print(\"y shape:\", dataset[0].y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.A. Preprocessing\n",
    "The mesh is augmented with world edges, nodes that are close in world space are connected to model collisions.\n",
    "Originally two separate edge MLPs are learned for this purpose, however indicating whether an edge belongs to the mesh- or world graph as part of the edge features is equally as expressive and this step therefore ignored in our reimplementation.\n",
    "In addition the graph is remeshed as described in II.C\n",
    "The authors (deepmind) work with the tensorflow TFrecord data format, we use Rayan Kanfar's (https://github.com/kanfarrs/) translation code to obtain torch compatible data.\n",
    "Dataset statistics (mean + std dev) are collected from train data and applied to normalize at inference.\n",
    "The model operates on relative coordinates for robustness.\n",
    "Additionally, all features are normalized to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(data_list):\n",
    "    '''\n",
    "    Taken from:\n",
    "    https://colab.research.google.com/drive/1mZAWP6k9R0DE5NxPzF8yL2HpIUG3aoDC?usp=sharing\n",
    "\n",
    "    Method for normalizing processed datasets. Given  the processed data_list,\n",
    "    calculates the mean and standard deviation for the node features, edge features,\n",
    "    and node outputs, and normalizes these using the calculated statistics.\n",
    "    '''\n",
    "\n",
    "    #mean and std of the node features are calculated\n",
    "    mean_vec_x=torch.zeros(data_list[0].x.shape[1:])\n",
    "    std_vec_x=torch.zeros(data_list[0].x.shape[1:])\n",
    "\n",
    "    #mean and std of the edge features are calculated\n",
    "    mean_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n",
    "    std_vec_edge=torch.zeros(data_list[0].edge_attr.shape[1:])\n",
    "\n",
    "    #mean and std of the output parameters are calculated\n",
    "    mean_vec_y=torch.zeros(data_list[0].y.shape[1:])\n",
    "    std_vec_y=torch.zeros(data_list[0].y.shape[1:])\n",
    "\n",
    "    #Define the maximum number of accumulations to perform such that we do\n",
    "    #not encounter memory issues\n",
    "    max_accumulations = 10**6\n",
    "\n",
    "    #Define a very small value for normalizing to\n",
    "    eps=torch.tensor(1e-8)\n",
    "\n",
    "    #Define counters used in normalization\n",
    "    num_accs_x = 0\n",
    "    num_accs_edge=0\n",
    "    num_accs_y=0\n",
    "\n",
    "    #Iterate through the data in the list to accumulate statistics\n",
    "    for dp in data_list:\n",
    "\n",
    "        #Add to the\n",
    "        mean_vec_x+=torch.sum(dp.x,dim=0)\n",
    "        std_vec_x+=torch.sum(dp.x**2,dim=0)\n",
    "        num_accs_x+=dp.x.shape[0]\n",
    "\n",
    "        mean_vec_edge+=torch.sum(dp.edge_attr,dim=0)\n",
    "        std_vec_edge+=torch.sum(dp.edge_attr**2,dim=0)\n",
    "        num_accs_edge+=dp.edge_attr.shape[0]\n",
    "\n",
    "        mean_vec_y+=torch.sum(dp.y,dim=0)\n",
    "        std_vec_y+=torch.sum(dp.y**2,dim=0)\n",
    "        num_accs_y+=dp.y.shape[0]\n",
    "\n",
    "        if(num_accs_x>max_accumulations or num_accs_edge>max_accumulations or num_accs_y>max_accumulations):\n",
    "            break\n",
    "\n",
    "    mean_vec_x = mean_vec_x/num_accs_x\n",
    "    std_vec_x = torch.maximum(torch.sqrt(std_vec_x/num_accs_x - mean_vec_x**2),eps)\n",
    "\n",
    "    mean_vec_edge = mean_vec_edge/num_accs_edge\n",
    "    std_vec_edge = torch.maximum(torch.sqrt(std_vec_edge/num_accs_edge - mean_vec_edge**2),eps)\n",
    "\n",
    "    mean_vec_y = mean_vec_y/num_accs_y\n",
    "    std_vec_y = torch.maximum(torch.sqrt(std_vec_y/num_accs_y - mean_vec_y**2),eps)\n",
    "\n",
    "    mean_std_list=[mean_vec_x,std_vec_x,mean_vec_edge,std_vec_edge,mean_vec_y,std_vec_y]\n",
    "\n",
    "    return mean_std_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Architecture\n",
    "The chosen architecture is very similar to unnormalized graph convolution, with the addition of edge embeddings.\n",
    "First nodes and edges are embedded, then in a number of processing steps the embeddings are updated according to adjacency.\n",
    "At each step the edge embeddings are updated via MLP of concatenated adjacent nodes + residual.\n",
    "Then the node embeddings are updated via MLP of previous node embedding concatenated with the edge embeddings + residual.\n",
    "Finally the node embeddings are decoded for the quantity of interest (f.e. velocity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ProcessingLayer(MessagePassing):\n",
    "    def __init__(self, node_dim, edge_dim):\n",
    "        super().__init__()\n",
    "        self.node_mlp = nn.Sequential(\n",
    "                nn.Linear(2*node_dim, node_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(node_dim, node_dim),\n",
    "                nn.LayerNorm(node_dim),\n",
    "            )\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "                nn.Linear(2*node_dim+edge_dim, edge_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(edge_dim, edge_dim),\n",
    "                nn.LayerNorm(edge_dim),\n",
    "            )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in [0,2]:\n",
    "            self.node_mlp[i].reset_parameters()\n",
    "            self.edge_mlp[i].reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, size=None):\n",
    "        \"\"\"\n",
    "        Propagate messages to update embeddings.\n",
    "\n",
    "        Args:\n",
    "        x [n_nodes, node_dim]: node embeddings\n",
    "        edge_index [2, n_edges]\n",
    "        edge_attr [E, edge_dim]\n",
    "\n",
    "        \"\"\"\n",
    "        # edge update\n",
    "        out, updated_edges = self.propagate(edge_index=edge_index, x=x, edge_attr=edge_attr, size=size)\n",
    "\n",
    "        # residual and node update\n",
    "        updated_nodes = x + self.node_mlp(torch.cat([x, out], dim=1))\n",
    "        return updated_nodes, updated_edges\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        This computes the message to be passed from node i to node j.\n",
    "        x_i [E, node_dim]: source node embedding \n",
    "        x_j [E, node_dim]: target node embedding \n",
    "        edge_attr [E, edge_dim]\n",
    "        \"\"\"\n",
    "        updated_edges = torch.cat([x_i, x_j, edge_attr], dim=1)\n",
    "        # edge update with residual\n",
    "        return self.edge_mlp(updated_edges) + edge_attr\n",
    "\n",
    "    def aggregate(self, updated_edges, edge_index, dim_size=None):\n",
    "        \"\"\"\n",
    "        This aggregates the messages from all the neighbors by addition.\"\"\"\n",
    "        # scatter add without dependency\n",
    "        src = updated_edges\n",
    "        out_size = list(src.size())\n",
    "        out_size[0] = edge_index.max().item()+1\n",
    "        out = torch.zeros(out_size, dtype=src.dtype, device=src.device)\n",
    "        out.index_add_(dim=0, index=edge_index[0, :], source=src)\n",
    "        return out, updated_edges\n",
    "\n",
    "\n",
    "class MeshGraphNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim_node,\n",
    "            input_dim_edge,\n",
    "            output_dim,\n",
    "            args,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.num_layers = args[\"num_layers\"]\n",
    "        self.hidden_dim = args[\"hidden_dim\"]\n",
    "        self.node_encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim_node, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                nn.LayerNorm(self.hidden_dim),\n",
    "            )\n",
    "\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim_edge, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                nn.LayerNorm(self.hidden_dim),\n",
    "            )\n",
    "\n",
    "        self.processor_blocks = []\n",
    "        for _ in range(self.num_layers):\n",
    "            self.processor_blocks.append(ProcessingLayer(self.hidden_dim, self.hidden_dim))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "                nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.hidden_dim, output_dim)\n",
    "                )\n",
    "\n",
    "    def forward(self, data, mean_x, std_x, mean_edge, std_edge):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        # normalize nodes and edges\n",
    "        x = (x-mean_x)/std_x\n",
    "        edge_attr = (edge_attr-mean_edge)/std_edge\n",
    "\n",
    "\n",
    "        # encode nodes and edges\n",
    "        x = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # update embeddings using processor layers\n",
    "        for layer in self.processor_blocks:\n",
    "            x, edge_attr = layer(x, edge_index, edge_attr)\n",
    "\n",
    "        # decode node embeddings\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def loss(self, pred, inputs, mean_y, std_y):\n",
    "        # normalize labels\n",
    "        labels = (inputs.y-mean_y)/std_y\n",
    "\n",
    "        # create mask for nodes of interest\n",
    "        loss_mask = torch.logical_or((torch.argmax(inputs.x[:,2:],dim=1)==NodeType.NORMAL),\n",
    "                                    (torch.argmax(inputs.x[:,2:],dim=1)==NodeType.OUTFLOW))\n",
    "\n",
    "        # calculate total error \n",
    "        loss = torch.sum((labels-pred)**2, axis=1)\n",
    "        # mask and mean\n",
    "        return torch.mean(loss[loss_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 10\n",
    "TEST_SIZE = 2\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "ARGS = {\n",
    "    \"num_layers\": 10,\n",
    "    \"batch_size\": 16,\n",
    "    \"hidden_dim\": 10,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 5e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset[:TRAIN_SIZE])\n",
    "# testloader = DataLoader(dataset[TRAIN_SIZE:TRAIN_SIZE+TEST_SIZE])\n",
    "\n",
    "[mean_x,std_x,mean_edge,std_edge,mean_y,std_y] = list(map(lambda x: x.to(DEVICE), get_stats(dataset)))\n",
    "\n",
    "model = MeshGraphNet(\n",
    "        input_dim_node=dataset[0].x.shape[1],\n",
    "        input_dim_edge=dataset[0].edge_attr.shape[1],\n",
    "        output_dim=2, # velocity\n",
    "        args=ARGS,\n",
    "        )\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "opt = torch.optim.Adam(trainable_params, lr=ARGS[\"lr\"], weight_decay=ARGS[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## V. Results\n",
    "MeshGraphNets deliver accurate long rollouts at speeds up to two orders of magnitude faster than the solvers. They outperform particle-based and grid-based baselines, with smaller errors in challenging regimes. They also scale and generalize well at inference, enabling simulations larger than or fundamentally different from anything seen in training.\n",
    "\n",
    "## VI. Tricks\n",
    "\n",
    "### VI.A Training Noise\n",
    "To improve rollout stability, noise can be injected during training, nudging the model towards self correcting behavior.\n",
    "As small predictions inevitably accumulate at inference, the authors report that a model used to noisy environments is much more robust to this.\n",
    "Empirically predictions stay plausible even after tens of thousands of rollout steps.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar-meshgraphnets-1a9JqSEb-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
